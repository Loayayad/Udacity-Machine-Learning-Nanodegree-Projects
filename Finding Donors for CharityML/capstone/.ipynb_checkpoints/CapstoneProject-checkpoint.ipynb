{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Udacity Machine Learning Nanodegree Capstone Project\n",
    "## Bank Marketing Campaign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The challenge is to design a model that will be able to predict whether a customer will respond to the marketing campaign based on his/her information. I will predict the `responded` target variable based on all the input variables provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The flow of the document will be in the following manner:\n",
    "- Exploring the Data\n",
    "- Data preprocessing/cleaning\n",
    "- Evaluate Algorithms\n",
    "- Model Tuning to Improve Result\n",
    "- Final conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Exploring the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Loading Libraries and data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T19:17:24.138959",
     "start_time": "2017-08-04T19:17:23.895302"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f37eeecc05ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplotting\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscatter_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtime\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from time import time\n",
    "from IPython.display import display\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "%matplotlib inline\n",
    "\n",
    "# Load the dataset\n",
    "in_file = 'full_data.csv'\n",
    "full_data = pd.read_csv(in_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Peek at the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T19:17:27.087014",
     "start_time": "2017-08-04T19:17:26.999998"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print the first few entries of the Email Marketing Challenge data\n",
    "display(full_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T19:17:30.674563",
     "start_time": "2017-08-04T19:17:30.610728"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "full_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Dimensions of data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T19:17:32.744814",
     "start_time": "2017-08-04T19:17:32.741811"
    }
   },
   "outputs": [],
   "source": [
    "print(\"The training dataset has\",full_data.shape[1],\"columns and\", full_data.shape[0],\"rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Overview of responses and overall response rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T19:17:34.697602",
     "start_time": "2017-08-04T19:17:34.668116"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate number of customers\n",
    "n_customers = len(full_data)\n",
    "\n",
    "# Calculate number of features\n",
    "n_features = len(full_data.columns[:-1])     # 30 Feature cols and 1 target col \n",
    "\n",
    "# Calculate reponded customers\n",
    "n_subscribed = len(full_data[full_data['y'] == 'yes'])\n",
    "\n",
    "# Calculate not responded customers\n",
    "n_not_subscribed = len(full_data[full_data['y'] == 'no'])\n",
    "\n",
    "# Calculate response rate\n",
    "response_rate = n_subscribed/(n_customers)*100\n",
    "\n",
    "# Print the results\n",
    "print(\"Total number of customers: {}\".format(n_customers))\n",
    "print(\"Number of features: {}\".format(n_features))\n",
    "print(\"Number of customers who subscribed: {}\".format(n_subscribed))\n",
    "print(\"Number of customers who did not subscribe: {}\".format(n_not_subscribed))\n",
    "print(\"Response rate of customers: {:.2f}%\".format(response_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Statistical Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T19:17:37.157559",
     "start_time": "2017-08-04T19:17:37.099606"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(full_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Exploratory Analysis - Data Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T19:17:39.159142",
     "start_time": "2017-08-04T19:17:39.155244"
    }
   },
   "outputs": [],
   "source": [
    "full_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T19:17:41.368512",
     "start_time": "2017-08-04T19:17:41.007130"
    }
   },
   "outputs": [],
   "source": [
    "#histogram\n",
    "h = sns.distplot(full_data['age'], bins=10, kde=False)\n",
    "plt.title('Age distribution in the data')\n",
    "h.figure.set_size_inches(16,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T19:21:51.412974",
     "start_time": "2017-08-04T19:21:49.575587"
    }
   },
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5)\n",
    "g = sns.FacetGrid(full_data, col=\"marital\", col_wrap=2, height=5, aspect=1.5)  \n",
    "g.map(sns.boxplot, \"job\",\"duration\").set_xticklabels(rotation=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T19:21:55.708704",
     "start_time": "2017-08-04T19:21:54.633458"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5)\n",
    "g = sns.FacetGrid(full_data, col=\"marital\", col_wrap=2, size=6, aspect=1.5)  \n",
    "g.map(sns.distplot, \"age\", bins=10).set_xticklabels(rotation=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T19:22:07.972321",
     "start_time": "2017-08-04T19:21:58.767149"
    }
   },
   "outputs": [],
   "source": [
    "#'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed'\n",
    "sns.set(font_scale=1.5)\n",
    "g = sns.pairplot(full_data[[\"age\", \"duration\", \"marital\", \"campaign\",\"euribor3m\"]], hue=\"marital\", diag_kind=\"hist\", size=4)  \n",
    "for ax in g.axes.flat:  \n",
    "    plt.setp(ax.get_xticklabels(), rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T19:22:24.143779",
     "start_time": "2017-08-04T19:22:10.805943"
    }
   },
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5)\n",
    "g = sns.PairGrid(full_data[[\"age\", \"duration\", \"marital\", \"euribor3m\"]], hue=\"marital\", size=5)  \n",
    "g.map_upper(sns.regplot)  \n",
    "g.map_lower(sns.residplot)  \n",
    "g.map_diag(plt.hist)  \n",
    "for ax in g.axes.flat:  \n",
    "    plt.setp(ax.get_xticklabels(), rotation=45)\n",
    "g.add_legend()  \n",
    "g.set(alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T19:22:33.959070",
     "start_time": "2017-08-04T19:22:27.310518"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5)\n",
    "g = sns.JointGrid(x=\"campaign\", y=\"duration\", data=full_data, size=6)  \n",
    "g.plot_joint(sns.regplot, order=2)  \n",
    "g.plot_marginals(sns.distplot)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T19:22:37.583204",
     "start_time": "2017-08-04T19:22:37.018855"
    }
   },
   "outputs": [],
   "source": [
    "# visulize correlations of features with a heatmap\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(full_data.corr())\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(rotation=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Preprocessing/Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, I will prepare the data by splitting feature and target/label columns and also check for quality of given data and perform data cleaning. \n",
    "To check if the model I created is any good, I will split the data into `training` and `validation` sets to check the accuracy of the best model. We will split the given `training` data in two ,70% of which will be used to train our models and 30% we will hold back as a `validation` set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Preprocess Feature Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there are several non-numeric columns that need to be converted! Many of them are simply yes/no, e.g. housing. These can be reasonably converted into 1/0 (binary) values.\n",
    "Other columns, like profession and marital, have more than two values, and are known as categorical variables. The recommended way to handle such a column is to create as many columns as possible values (e.g. profession_admin, profession_blue-collar,  etc.), and assign a 1 to one of them and 0 to all others.\n",
    "These generated columns are sometimes called dummy variables, and we will use the pandas.get_dummies() function to perform this transformation. The code cell below performs the preprocessing routine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-22T17:57:21.376825",
     "start_time": "2017-07-22T17:57:21.128550"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def preprocess_features(X):\n",
    "    ''' Preprocesses the student data and converts non-numeric binary variables into\n",
    "        binary (0/1) variables. Converts categorical variables into dummy variables. '''\n",
    "    \n",
    "    # Initialize new output DataFrame\n",
    "    output = pd.DataFrame(index = X.index)\n",
    "\n",
    "    # Investigate each feature column for the data\n",
    "    for col, col_data in X.iteritems():\n",
    "        \n",
    "        # If data type is non-numeric, replace all yes/no values with 1/0\n",
    "        if col_data.dtype == object:\n",
    "            col_data = col_data.replace(['yes', 'no','unknown'], [1, 0, np.nan])\n",
    "\n",
    "        # If data type is categorical, convert to dummy variables\n",
    "        if col_data.dtype == object:\n",
    "            col_data = pd.get_dummies(col_data, prefix = col)  \n",
    "        \n",
    "        # Collect the revised columns\n",
    "        output = output.join(col_data)\n",
    "    \n",
    "    return output\n",
    "\n",
    "full_data = preprocess_features(full_data)\n",
    "print(\"Processed feature columns ({} total features):\\n{}\".format(len(full_data.columns), list(full_data.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Identify feature and target columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-22T17:57:26.309402",
     "start_time": "2017-07-22T17:57:26.277361"
    },
    "run_control": {
     "marked": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Extract feature columns\n",
    "feature_cols = list(full_data.columns[:-1])\n",
    "\n",
    "# Extract target column 'responded'\n",
    "target_col = full_data.columns[-1] \n",
    "\n",
    "# Show the list of columns\n",
    "print(\"Feature columns:\\n{}\".format(feature_cols))\n",
    "print(\"\\nTarget column: {}\".format(target_col))\n",
    "\n",
    "# Separate the data into feature data and target data (X_all and y_all, respectively)\n",
    "X_all = full_data[feature_cols]\n",
    "y_all = full_data[target_col]\n",
    "\n",
    "# Show the feature information by printing the first five rows\n",
    "print(\"\\nFeature values:\")\n",
    "print(X_all.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Data cleaning/washing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how many missing values our dataset now has..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-22T17:57:31.282629",
     "start_time": "2017-07-22T17:57:31.228355"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_all.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So looks like we have 4 columns that have missing values.\n",
    "\n",
    "`default`, `housing` and `loan` are the four columns that has the most missing values but instead of dropping these altogether I will try to impute them as they may hold relevant information for the dataset. `nr.employed` has too many missing so we will go ahead and drop it.\n",
    "To fill missing values, We will use `median` statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-22T18:00:31.493070",
     "start_time": "2017-07-22T18:00:31.189737"
    }
   },
   "outputs": [],
   "source": [
    "X_all.drop('nr.employed',  axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-22T17:59:44.439012",
     "start_time": "2017-07-22T17:59:29.180237"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_all.fillna(X_all.median(), inplace=True)\n",
    "X_all.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-22T18:01:10.707208",
     "start_time": "2017-07-22T18:01:10.704112"
    },
    "run_control": {
     "marked": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Processed feature columns ({} total features):\\n{}\".format(len(X_all.columns), list(X_all.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-22T18:01:23.285132",
     "start_time": "2017-07-22T18:01:21.979240"
    }
   },
   "outputs": [],
   "source": [
    "# Export cleaned data\n",
    "\n",
    "filename = 'cleaned_X_all.csv'\n",
    "X_all.to_csv(filename, index=False, encoding='utf-8')\n",
    "filename = 'cleaned_y_all.csv'\n",
    "y_all.to_csv(filename, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-02T16:32:03.592151",
     "start_time": "2017-08-02T16:32:03.304294"
    }
   },
   "outputs": [],
   "source": [
    "# Read cleaned data directly\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series\n",
    "import seaborn as sns\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from IPython.display import display\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "in_file = 'cleaned_X_all.csv'\n",
    "X_all = pd.read_csv(in_file)\n",
    "in_file = 'cleaned_y_all.csv'\n",
    "y_all = pd.read_csv(in_file, squeeze=True, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Training and Validation Data Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, I have converted all categorical features into numeric values. For the next step, I will split the data (both features and corresponding labels) into training and test sets. In the code cell below, we will implement the following:\n",
    " - Randomly shuffle and split the data (`X_all, y_all`) into training and validation subsets.\n",
    " - Split training and validation into 70% and 30%.\n",
    " - Set a `random_state` for the function(s).\n",
    " - Store the results in `X_train, X_validation, y_train` and `y_validation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-02T16:32:16.800627",
     "start_time": "2017-08-02T16:32:16.761681"
    },
    "code_folding": [],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "validation_size = 0.30\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_all, y_all, stratify = y_all, \n",
    "                                                    test_size = validation_size, random_state = 123)\n",
    "print(\"Train set 'yes' pct = {:.2f}%\".format(100 * (y_train == 1).mean()))\n",
    "print(\"Validation  set 'yes' pct = {:.2f}%\".format(100 * (y_validation == 1).mean()))\n",
    "\n",
    "# Show the results of the split\n",
    "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print(\"Validation set has {} samples.\".format(X_validation.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Evaluating Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't know which algorithms would be good on this problem or what configurations to use. So let's pick a few algorithms to evaluate.\n",
    " - Logistic Regression (LR)\n",
    " - Classification and Regression Trees (CART)\n",
    " - Random Forests (RF)\n",
    " - Adaptive Boosting (AB)\n",
    " - Extreme Gradient Boosting (XGB)\n",
    " \n",
    "We are using 10-fold cross validation to estimate accuracy. This will split our dataset 10 parts, train on 9 and test on 1 and repeat for all combinations of train-test splits.\n",
    " \n",
    "Also, we are using the metric of `accuracy` to evaluate models. This is a ratio of the number of correctly predicted instances in divided by the total number of instances in the dataset multiplied by 100 to give a percentage (e.g. 95% accurate). We will be using the `scoring` variable when we run build and evaluate each model next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test to check how XGBoost compares with SKLearn wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-02T16:33:01.419006",
     "start_time": "2017-08-02T16:32:58.426028"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test to check how XGBoost compares with SKLearn wrapper\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "clf = XGBClassifier()\n",
    "param = clf.get_xgb_params()\n",
    "clf.fit(X_train, y_train)\n",
    "preds_sk = clf.predict(X_validation)\n",
    "\n",
    "import xgboost as xgb\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dvalid = xgb.DMatrix(X_validation)\n",
    "bst = xgb.train(param, dtrain)\n",
    "preds = bst.predict(dvalid).round()\n",
    "\n",
    "print(\"Accurary of sklearn wrapper: \",accuracy_score(y_validation, preds_sk))\n",
    "print(\"Accuracy of XGBoost library: \",accuracy_score(y_validation, preds.round()))\n",
    "print(\"---------------------------------------------\")\n",
    "print(\"sklearn predictions: \", preds_sk)\n",
    "print(\"XGB library predictions: \",preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of sklearn wrapper is much better so we would use that going forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Build Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-02T16:34:26.241101",
     "start_time": "2017-08-02T16:33:13.895821"
    },
    "run_control": {
     "marked": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scoring = 'accuracy'\n",
    "\n",
    "#Spot check algorithms\n",
    "models = []\n",
    "models.append(('1. LR', LogisticRegression()))\n",
    "models.append(('2. CART', DecisionTreeClassifier()))\n",
    "models.append(('3. RF', RandomForestClassifier(n_estimators=100)))\n",
    "models.append(('4. AB', AdaBoostClassifier(RandomForestClassifier(n_estimators=100), \n",
    "                                        algorithm='SAMME',n_estimators=100, learning_rate=1.0)))\n",
    "#models.append(('5. XGB', XGBClassifier()))\n",
    "# Evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits = 10, random_state = 123)\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, y_train,\n",
    "                                                cv = kfold, \n",
    "                                                 scoring = scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Select Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have 5 models and accuracy estimations for each. We need to compare the models to each other and select the most accurate. The output of above code cell shows `XGB` being the winner with highest estimated accuracy score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot below shows model evaluation results and compare the spread and the mean accuracy of each model. There is a population of accuracy measures for each algorithm beacuse each algortihm was evaluated 10 times (10 fold cross validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-02T16:34:32.852837",
     "start_time": "2017-08-02T16:34:32.600333"
    }
   },
   "outputs": [],
   "source": [
    "# Compare Algorithms\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The box and whisker plots are aligned at the top of the range near ~91% mark but appears `CART` is low performer and hovering in the ~89% range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Make predictions on the validation set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `XGB` model was the most accurate model that we tested. Now we want to get an idea of accuracy of the model on our validation set.\n",
    "This will give us an independent final check on the accuracy of th best model.\n",
    "\n",
    "We can run the `XGB` model directly on the validation set and summarize the results as a final accuracy score, a confusion matrix and a classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-02T16:34:50.932143",
     "start_time": "2017-08-02T16:34:48.152646"
    },
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select best model\n",
    "# Make predictions on validation dataset\n",
    "xgb = XGBClassifier()\n",
    "fit = xgb.fit(X_train, y_train)\n",
    "xgb.pred = xgb.predict(X_validation)\n",
    "print(\"Accuracy Score: \",accuracy_score(y_validation, xgb.pred))\n",
    "print(\"----------------------------------------------------------\")\n",
    "print(\"Confusion Matrix: \\n\",confusion_matrix(y_validation, xgb.pred))\n",
    "print(\"----------------------------------------------------------\")\n",
    "print(\"Classification Report: \\n\",classification_report(y_validation, xgb.pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the accuracy is 0.918 or 91.8%. The confusion matrix provides an indication of the prediction errors made. Finally the classification report provides a breakdown of each class by precision, recall, f1-score and support."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-13T13:20:41.313315",
     "start_time": "2017-06-13T13:20:41.306323"
    }
   },
   "source": [
    "Let's starting with some tuning parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-02T16:37:42.861850",
     "start_time": "2017-08-02T16:37:33.672572"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "from xgboost import plot_tree\n",
    "from matplotlib.pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# fit model\n",
    "model = XGBClassifier(seed = 123)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# printing the model for visualization\n",
    "print(model)\n",
    "\n",
    "# plot single tree\n",
    "rcParams['figure.figsize'] = 80,50\n",
    "\n",
    "plot_tree(model) #, rankdir='LR'\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-02T16:38:31.862205",
     "start_time": "2017-08-02T16:38:16.412706"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tune objective\n",
    "param_set0 = {\n",
    "    'objective': ('reg:linear', 'binary:logistic','count:poisson')\n",
    "}\n",
    "\n",
    "xgb0 = XGBClassifier(silent=True, nthread=-1, max_delta_step=0.7, seed=123)\n",
    "\n",
    "gsearch0 = GridSearchCV(estimator=xgb0, param_grid=param_set0, scoring='roc_auc', n_jobs=4, cv=5) #verbose=2\n",
    "gsearch0.fit(X_train, y_train)\n",
    "print(gsearch0.grid_scores_)\n",
    "print(\"----------------------------------------------------\")\n",
    "print(gsearch0.best_params_)\n",
    "print(\"----------------------------------------------------\")\n",
    "print(gsearch0.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-02T16:43:26.036813",
     "start_time": "2017-08-02T16:38:37.350460"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tune max_depth and min_child_weight\n",
    "\n",
    "param_test1 = {\n",
    "    'max_depth': [3,4,5,6,7,8,9],\n",
    "    'min_child_weight': [2,3,4,5,6,7]\n",
    "}\n",
    "\n",
    "xgb1 = XGBClassifier(silent=True, nthread=-1, max_delta_step=0.7, seed=0, objective='reg:linear')\n",
    "gsearch1 = GridSearchCV(estimator = xgb1, param_grid = param_test1, scoring = 'roc_auc', n_jobs = 4, \n",
    "                        iid = False, cv = 5)\n",
    "gsearch1.fit(X_train,y_train)\n",
    "\n",
    "#print(gsearch1.grid_scores_)\n",
    "print(\"----------------------------------------------------\")\n",
    "print(gsearch1.best_params_)\n",
    "print(\"----------------------------------------------------\")\n",
    "print(gsearch1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-02T16:47:30.989447",
     "start_time": "2017-08-02T16:46:33.708807"
    }
   },
   "outputs": [],
   "source": [
    "# Tune gamma\n",
    "param_test2 = {\n",
    "    'gamma':[i/10.0 for i in range(1,10,1)]\n",
    "}\n",
    "\n",
    "xgb2 = XGBClassifier(silent=True, nthread=-1, max_delta_step=0.7, seed=0, objective='reg:linear', \n",
    "                     max_depth=5, min_child_weight=3)\n",
    "gsearch2 = GridSearchCV(estimator = xgb2, param_grid = param_test2, scoring = 'roc_auc',n_jobs = 4,\n",
    "                         iid = False, cv = 5)\n",
    "gsearch2.fit(X_train,y_train)\n",
    "\n",
    "print(gsearch2.grid_scores_)\n",
    "print(\"----------------------------------------------------\")\n",
    "print(gsearch2.best_params_)\n",
    "print(\"----------------------------------------------------\")\n",
    "print(gsearch2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-02T16:49:19.436138",
     "start_time": "2017-08-02T16:48:21.200019"
    }
   },
   "outputs": [],
   "source": [
    "# Tune reg_alpha and reg_lambda\n",
    "param_test3 = {\n",
    "    'reg_alpha': (0,2,4),\n",
    "    'reg_lambda': (1,3,5)\n",
    "}\n",
    "\n",
    "xgb3 = XGBClassifier(silent=True, nthread=-1, max_delta_step=0.7, seed=0, objective='reg:linear', \n",
    "                     max_depth=5, min_child_weight=3, gamma=0.1)\n",
    "gsearch3 = GridSearchCV(estimator = xgb3, param_grid = param_test3, scoring = 'roc_auc',n_jobs = 4,\n",
    "                         iid = False, cv = 5)\n",
    "gsearch3.fit(X_train,y_train)\n",
    "\n",
    "print(gsearch3.grid_scores_)\n",
    "print(\"----------------------------------------------------\")\n",
    "print(gsearch3.best_params_)\n",
    "print(\"----------------------------------------------------\")\n",
    "print(gsearch3.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-02T16:51:45.868237",
     "start_time": "2017-08-02T16:51:06.783499"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Tune subsample, colsample_bytree and colsample_bylevel\n",
    "param_test4 = {\n",
    "    'subsample': (0.5, 1),\n",
    "    'colsample_bytree': (0.5, 1),\n",
    "    'colsample_bylevel': (0.5, 1)\n",
    "}\n",
    "\n",
    "xgb4 = XGBClassifier(silent=True, nthread=-1, max_delta_step=0.7, seed=0, objective='reg:linear', \n",
    "                     max_depth=5, min_child_weight=3, gamma=0.1, reg_alpha=2, reg_lambda=5)\n",
    "gsearch4 = GridSearchCV(estimator = xgb4, param_grid = param_test4, scoring = 'roc_auc',n_jobs = 4,\n",
    "                         iid = False, cv = 5)\n",
    "gsearch4.fit(X_train,y_train)\n",
    "\n",
    "print(gsearch4.grid_scores_)\n",
    "print(\"----------------------------------------------------\")\n",
    "print(gsearch4.best_params_)\n",
    "print(\"----------------------------------------------------\")\n",
    "print(gsearch4.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-04T19:33:58.743991",
     "start_time": "2017-08-04T19:33:57.061368"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(font_scale = 2.0)\n",
    "ax = xgb.plot_importance(tuned_model)\n",
    "fig = ax.figure\n",
    "fig.set_size_inches(15,20)\n",
    "plt.savefig('../feat_imp.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions on the validation set based on tuned model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `XGB` model was the most accurate model that we tested. Now we want to get an idea of accuracy of the model on our validation set.\n",
    "This will give us an independent final check on the accuracy of th best model.\n",
    "\n",
    "We can run the `XGB` model directly on the validation set and summarize the results as a final accuracy score, a confusion matrix and a classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-02T16:52:07.620895",
     "start_time": "2017-08-02T16:52:03.377614"
    }
   },
   "outputs": [],
   "source": [
    "# Select best model\n",
    "# Make predictions on validation dataset using tuned parameters\n",
    "tuned_model = XGBClassifier(silent=True, nthread=-1, max_delta_step=0.7, seed=0, objective='reg:linear', \n",
    "                     max_depth=5, min_child_weight=3, gamma=0.1, reg_alpha=2, reg_lambda=5, subsample=1, \n",
    "                            colsample_bytree=1, colsample_bylevel=1)\n",
    "tuned_fit = tuned_model.fit(X_train, y_train)\n",
    "tuned_pred = tuned_model.predict(X_validation)\n",
    "\n",
    "print(\"Accuracy Score: \",accuracy_score(y_validation, tuned_pred))\n",
    "print(\"----------------------------------------------------------\")\n",
    "print(\"Confusion Matrix: \\n\",confusion_matrix(y_validation, tuned_pred))\n",
    "print(\"----------------------------------------------------------\")\n",
    "print(\"Classification Report: \\n\",classification_report(y_validation, tuned_pred))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
